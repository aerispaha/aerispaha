<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <link rel="canonical" href="https://www.adamerispaha.com/">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Adam Erispaha &middot; A blog
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- ga tracking -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-89047706-1', 'auto');
    ga('send', 'pageview');

  </script>
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="https://www.adamerispaha.com">
          Adam Erispaha
        </a>
      </h1>
      <p class="lead">Civil/environmental engineer, loves charts, data, urban hydrology, and Python</p>
    </div>

    <nav class="sidebar-nav">
      <!-- <a class="sidebar-nav-item" href="">Home</a> -->

      

      
      
        
          
        
      
        
      
        
          
        
      
        
          
        
      
        
      
        
      
        
      
        
          
        
      
        
          
        
      

      <a class="sidebar-nav-item" href="https://github.com/aerispaha">Github Projects</a>
      <a class="sidebar-nav-item" href="https://gist.github.com/aerispaha">Gists</a>

      <!-- <a class="sidebar-nav-item" href="https://gist.github.com/aerispaha/archive/v2.1.0.zip">Download</a> -->

    </nav>

    <!-- <p>2016 - 2021</p> -->
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/06/06/unjust-power-structures-ignore-calls-for-change-if-we-let-them/">
        Unjust power structures will ignore calls for change if we let them
      </a>
    </h1>

    <span class="post-date">06 Jun 2020</span>

    <p>Like most people, I’d prefer to see our communities come together, make things, learn, build, enjoy art, and coexist in harmony with each other and nature. But we obviously aren’t there yet.</p>

<p>Instead we have a reality in which <a href="https://americansfortaxfairness.org/issue/tale-two-crises-billionaires-gain-workers-feel-pandemic-pain/">American billionaires increased their wealth by $434B</a> while the rest of us have struggled to survive a global pandemic and economic depression. Where <a href="https://www.washingtonpost.com/graphics/investigations/police-shootings-database/">1000 people each year are killed</a> by increasingly militarized police forces, where black people are killed while sleeping in their homes, jogging, driving.</p>

<h3 id="power-asymmetry-and-violence">Power Asymmetry and Violence</h3>
<p>The murder of George Floyd set off a cascade of demonstrations spawning uprisings in every state in the US and in many countries around the world in the spring of 2020. The unrest renewed a discussion about the morality and efficacy of the tactics used by people in the streets:</p>
<ul>
  <li>Isn’t property destruction bad?</li>
  <li>Isn’t violence bad?</li>
  <li>Why are they destroying their cities?</li>
</ul>

<p>Setting aside the problems with these questions, I think most people would agree that, in a vacuum, person A inflicting harm on person B is immoral.</p>

<p>But, in the real word, we have to consider the mountains of inequality between actors: some have more wealth than entire nations, some have ancestry from centuries of chattel slavery, some are killed by agents of the state, some <a href="https://theintercept.com/2020/04/01/philadelphia-hahnemann-hospital-joel-freedman/">profit by closing community hospitals</a>, some have legal teams, some can’t post bail, some can’t afford insulin, some poison the air that others breath, some write laws, some can’t vote, some work from home, some are essential workers, some suffer under broad systemic racism, others benefit from it.</p>

<p>This power asymmetry, in my view, is what matters most when we think about what tactics are strategic and moral toward the goal of achieving positive change.</p>

<p>First, let’s assume that the behavior of the system, with respect to power, follows a couple rules:</p>

<ul>
  <li>agents with power benefit from the status quo and by squeezing more power out of the system</li>
  <li>agents with power don’t voluntarily relinquish power</li>
  <li>money is power</li>
</ul>

<p>Given this, if demands on an unjust power structure can be ignored, they will be. Gains for regular people happen when their demands and actions can’t be ignored by the status quo and established power. This is why direct action that threatens, inflicts harm, costs, or at least inconveniences our opponents works. This is why it is effective to block traffic and shut down oil pipeline worksites. It stops business-as-usual, demands attention, and increases negotiating power.</p>

<p>I think much of the vandalism, broken windows, burned police stations, and looting is the manifestation of valid disgust and anger at an unjust system. Regardless of how valid or logical a human response one considers these uprisings, the fact that they are not under control by the beneficiaries of the status quo is what makes them potent and effective.</p>

<h3 id="peaceful-protest">Peaceful Protest</h3>
<p>Imagine a peaceful march that poses no inconvenience to those standing in the way of police reform. One that obeys the curfews imposed by the police, that stays on the sidewalks, and doesn’t affect the rush hour traffic (one that offers a Pepsi to a cop). Organizers can try to control the narrative and hope that the media reports sympathetically, that the police might be interested and open to listening to the activists’ speeches. Maybe the police chief will see the signatures on the petition and reevaluate their life’s work. Maybe its possible to appeal to the morality of officials to find legislative solutions.</p>

<p>I’m not suggesting that there aren’t alternatives to burning police cars and looting Walmarts. There are. But I do think we’ve waited long enough for demands to be heard and for police to stop murdering black people.</p>

<h3 id="our-opponents-are-ruthless">Our Opponents are Ruthless</h3>
<p>If the tactics taken by the 2020 uprising seem too violent, consider the tactics used by our opponents: tear gas, rubber bullets, bullets, tanks, drones, mass surveillance, from Jim Crow, to the assassination of Fred Hampton, Martin Luther King Jr., lynchings past and present. Consider the lengths Charles Koch was willing to go to dismantle labor and environmental protections, and the ruthlessness of Jeff Bezos, the dishonesty of big tobacco, Exxon Mobile. Our opponents are not sitting idly by, patiently waiting to cast their ballot every 4 years. They are hardcore. They are radical activists fighting violently for power and self-preservation.</p>

<p>We’ve been in an unfair fight for decades - unless we recognize that and fight back we are going to continue to lose.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2020/05/02/forgot-how-to-update-my-blog-for-2-years/">
        Forgot how to update my blog for 2 years
      </a>
    </h1>

    <span class="post-date">02 May 2020</span>

    <p>I’ve tried several times to develop a writing habit with varying levels of
success. But, after about a full year slump, I again forgot how to update my
blogo.</p>

<p>Over the years, my writing has lived in various types of infrastructure
(Myspace, Wordpress, notepad++, etc.) always tracking along with my evolving
coding tastes. In my PHP phase I was trying to blog with Laraval, for example.
The second-most recent iteration was the magic unicorn of Django, tracking
along with my ongoing love for Python.</p>

<h3 id="keep-it-simple">Keep it simple</h3>
<p>Somewhere along the line I grew frustrated with mental overhead necessary to
remember how to use Django anytime I felt inspired to write. This was exacerbated
by my writing inconsistency.</p>

<p>So, I had the brilliant idea to make things extremely simple: write in
markdown and host with GitHub pages. I use both tools daily, so what could
go wrong?</p>

<p>Then after many moons I forgot that I migrated my blog to this brilliant, simple
system. Over the next two years I was left intermittently trying to remember how
to log into the Django admin panel in an Django app that didn’t exist.</p>

<p>Yay!</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2017/07/22/media-coverage-dynamics-mongodb-python/">
        Measuring media coverage dynamics with MongoDB and Python
      </a>
    </h1>

    <span class="post-date">22 Jul 2017</span>

    <p>In a <a href="/2017/07/09/scraping-headlines-with-cronjobs-python-and-mongodb/">recent post</a>, I outlined a process that aims to capture the dynamics of the media landscape by taking a snapshot of news headlines every 15 minutes. The database has been quietly growing for about a month now, receiving data scraped from 19 media organizations’ RSS feeds while the world goes about its business. Even though we only have a sliver of headlines history to work with (about 30 days), we’re ready for some analysis.</p>

<p>Let’s start by taking a look at an example document in the MongoDB database representing a snapshot of USA Today’s RSS feed on June 12, 2017:</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
  <span class="dl">"</span><span class="s2">_id</span><span class="dl">"</span><span class="p">:</span> <span class="nx">ObjectId</span><span class="p">(</span><span class="dl">"</span><span class="s2">593e13134a5ac4327d88619c</span><span class="dl">"</span><span class="p">),</span>
  <span class="dl">"</span><span class="s2">datetime</span><span class="dl">"</span><span class="p">:</span> <span class="nx">datetime</span><span class="p">.</span><span class="nx">datetime</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">832000</span><span class="p">),</span>
  <span class="dl">"</span><span class="s2">source</span><span class="dl">"</span><span class="p">:</span> <span class="nx">u</span><span class="dl">"</span><span class="s2">usa_today</span><span class="dl">"</span><span class="p">,</span>
  <span class="dl">"</span><span class="s2">stories</span><span class="dl">"</span><span class="p">:</span> <span class="p">[</span>
    <span class="dl">"</span><span class="s2">'Dear Evan Hansen' wins six Tony Awards, including best musical</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">Penguins have become NHL's newest dynasty</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">First lady Melania Trump, son Barron officially move into the White House</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">E3 2017: The 5 biggest reveals during the Xbox event</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">Penguins repeat as Stanley Cup champions</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">Homophobic slur aimed at U.S. goalkeeper Brad Guzan by Mexican fans at World Cup qualifier</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">Ben Platt's reaction is the best GIF of the Tonys Awards</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">Puerto Ricans parade in New York, back statehood</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">Delta ends theater company sponsorship over Trump look-alike killing scene</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">U.S. earns rare tie vs. Mexico in World Cup qualifier at Estadio Azteca</span><span class="dl">"</span>
  <span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Within the document, we see a list of stories (i.e. news headlines) alongside the source (USA Today) and the datetime when the headlines were observed. As noted above, these snapshots are created every 15 minutes with data from the RSS feeds of 19 media organizations (<a href="/2017/07/09/scraping-headlines-with-cronjobs-python-and-mongodb/">see the list of feeds here</a>). At the time of writing, there are 29,925 of these snapshots in the database with headlines starting on June 12, 2017 (note: I lost all data between June 13 and July 5).</p>

<h2 id="querying-headlines-with-pymongo-and-pandas">Querying Headlines with PyMongo and Pandas</h2>
<p>In order to interact with the data, we construct a function, <code class="language-plaintext highlighter-rouge">query_rss_stories()</code> that wraps up the process of connecting to MongoDB, querying using the <a href="https://docs.mongodb.com/manual/aggregation/">aggregation framework</a> and regex, and organizing the results in a Pandas dataframe:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">query_rss_stories</span><span class="p">(</span><span class="n">regex</span><span class="p">):</span>

    <span class="c1">#connect to db
</span>    <span class="n">client</span> <span class="o">=</span> <span class="n">MongoClient</span><span class="p">()</span>
    <span class="n">news</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">news</span>
    <span class="n">headlines</span> <span class="o">=</span> <span class="n">news</span><span class="p">.</span><span class="n">headlines</span>

    <span class="c1">#query the database, create dataframe
</span>    <span class="n">pipeline</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s">"$unwind"</span><span class="p">:</span><span class="s">"$stories"</span><span class="p">},</span>
        <span class="p">{</span><span class="s">"$match"</span><span class="p">:{</span><span class="s">"stories"</span><span class="p">:{</span><span class="s">'$regex'</span><span class="p">:</span><span class="n">regex</span><span class="p">}}},</span>
        <span class="p">{</span><span class="s">"$project"</span><span class="p">:{</span><span class="s">"_id"</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s">"datetime"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s">"stories"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s">"source"</span><span class="p">:</span><span class="mi">1</span><span class="p">}}</span>
    <span class="p">]</span>

    <span class="c1">#unpack the cursor into a Dataframe
</span>    <span class="n">cursor</span> <span class="o">=</span> <span class="n">headlines</span><span class="p">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cursor</span><span class="p">])</span>

    <span class="c1">#round the rss query datetimes to 15mins
</span>    <span class="n">df</span><span class="p">.</span><span class="n">datetime</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="n">dt</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="s">'15min'</span><span class="p">)</span>
    <span class="n">raw_stories</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">set_index</span><span class="p">([</span><span class="s">'datetime'</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">raw_stories</span>
</code></pre></div></div>

<p>As an example, we’ll search for stories related to China:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stories</span> <span class="o">=</span> <span class="n">query_rss_stories</span><span class="p">(</span><span class="s">'China'</span><span class="p">)</span>
<span class="n">stories</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>source</th>
      <th>stories</th>
    </tr>
    <tr>
      <th>datetime</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-07-20 14:00:00</th>
      <td>breitbart</td>
      <td>Report: U.S. Bans Prompt American Allies to Bu...</td>
    </tr>
    <tr>
      <th>2017-07-14 05:45:00</th>
      <td>upi</td>
      <td>India rejects China's offer to mediate Kashmir...</td>
    </tr>
    <tr>
      <th>2017-07-13 00:15:00</th>
      <td>wsj_opinion</td>
      <td>How to Squeeze China</td>
    </tr>
    <tr>
      <th>2017-07-07 19:00:00</th>
      <td>abc</td>
      <td>US bombers fly over East and South China Seas</td>
    </tr>
    <tr>
      <th>2017-07-12 19:15:00</th>
      <td>reuters</td>
      <td>China dissident Liu's condition critical, brea...</td>
    </tr>
  </tbody>
</table>
</div>

<p>The <code class="language-plaintext highlighter-rouge">stories</code> dataframe contains all headlines related to China from all of the new sources starting around July 6. For every hour that a headline is live on a particular RSS feed, four entries will be found in the <code class="language-plaintext highlighter-rouge">stories</code> dataframe (since the snapshots are taken at 15-minute intervals).</p>

<p>Next, we unstack the data and count the number of China-related headlines found at each time step:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_rss_timeseries</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s">'1h'</span><span class="p">):</span>
    <span class="c1">#unstack sources and create headline_count time series
</span>    <span class="n">ts</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="n">headline_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">ts</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'datetime'</span><span class="p">,</span> <span class="s">'source'</span><span class="p">]).</span><span class="nb">sum</span><span class="p">()</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">ts</span><span class="p">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">level</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ts</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">ts</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1">#set time step
</span>    <span class="n">ts</span> <span class="o">=</span> <span class="n">ts</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="n">datetime</span> <span class="o">=</span> <span class="n">ts</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">ts</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'datetime'</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="n">freq</span><span class="p">)).</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">ts</span>

<span class="c1">#daily time series of China headline counts
</span><span class="n">ts</span> <span class="o">=</span> <span class="n">create_rss_timeseries</span><span class="p">(</span><span class="n">stories</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s">'1d'</span><span class="p">)</span>
</code></pre></div></div>

<p>To visualize, we create a stacked bar chart of China-related headline counts across all media organizations:
<img src="https://www.adamerispaha.com/assets/img/china-headlines-count.png" alt="China-Headlines-Count" />
Here, we can see that each day between July 7 and July 23, 2017, between 7 and 17 China-related headlines were found from 18 media sources. Sort of interesting, but what about a more volatile topic?</p>

<p>Let’s take a look at the volume of headlines related to “Trump Jr”. We’ll also increase the resolution thats visualized so we can see how the media coverage evolves each hour:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">jr_stories</span> <span class="o">=</span> <span class="n">query_rss_stories</span><span class="p">(</span><span class="s">'Trump Jr'</span><span class="p">)</span>
<span class="n">jr_ts</span> <span class="o">=</span> <span class="n">create_rss_timeseries</span><span class="p">(</span><span class="n">jr_stories</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s">'1h'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://www.adamerispaha.com/assets/img/trump-jr-headlines-count.png" alt="Trump-Junior-Headlines-Count" />
Now we’re seeing a major event play out.</p>

<h2 id="interpretations-and-future-work">Interpretations and Future Work</h2>
<p>Recording periodic snapshots allows us to observe how the media’s interest in a particular topic changes over time. For example, a topic that’s discussed simultaneously in multiple articles by many media organizations must be especially important at a given point in time. Similarly, an issue that is featured throughout the RSS feeds for many days are likely more significant than stories that come and go within a few hours. One can think of these dynamics like the intensity and duration of rainfall events: is there are drizzle or a deluge of articles, and for how long are the stories pattering down?</p>

<p>I’ve only scratched the surface, but there is a lot more I’d like to investigate now that I have a handle on the data. Future Work:</p>
<ul>
  <li>measure the proportion of attention given to particular topics</li>
  <li>quantify the differences in reporting between media organizations</li>
  <li>compare media attention to objectively important and quantifiable topics:
    <ul>
      <li>casualties of war</li>
      <li>bombings, shootings</li>
      <li>environmental disasters</li>
    </ul>
  </li>
  <li>natural language analysis
    <ul>
      <li>differences in sentiment on particular topics</li>
      <li>differences in sentiment between sources</li>
    </ul>
  </li>
  <li>identify any patterns between left- and right-leaning sources</li>
  <li>host data on public server and/or <a href="https://data.world/">data.world</a></li>
</ul>

  </div>
  
</div>


<div class="pagination">
  
    <span class="pagination-item older">Previous</span>
  

  
    <a  class="pagination-item newer" href="/page2">Next &raquo;</a>
  
</div>


      <!-- <p>&copy; 2021. All rights reserved.</p> -->
    </div>

  </body>
</html>
